audio:
  chunk_size: 261120
  num_channels: 2
  sample_rate: 44100
  min_mean_abs: 0.001

model:
  num_sources: 4 # Typically, vocals, bass, drums, other
  num_channels: 2 # Must match audio.num_channels
  time_win_size: 8192 # Larger window for higher frequency resolution
  time_hop_size: 1024 # Hop size set to 1024 (matches hop_length in mdxc23)
  time_ftr_size: 2000 # Increased feature dimension for time-domain processing
  spec_win_size: 8192
  spec_hop_size: 1024
  spec_fft_size: 8192 # Use a larger FFT for high-resolution spectral encoding
  rnn_hidden_size: 1000 # Hidden dimension for the LSTM blocks
  rnn_num_layers: 2 # Number of LSTM layers in each RNN block

training:
  batch_size: 6
  gradient_accumulation_steps: 6
  grad_clip: 0
  instruments:
    - vocals
    - bass
    - drums
    - other
  lr: 5.0e-05
  patience: 3
  reduce_factor: 0.95
  target_instrument: null
  num_epochs: 1000
  num_steps: 1000
  q: 0.95
  coarse_loss_clip: true
  ema_momentum: 0.999
  optimizer: adam
  other_fix: false
  use_amp: true

augmentations:
  enable: true # enable or disable all augmentations (to fast disable if needed)
  loudness: true # randomly change loudness of each stem on the range (loudness_min; loudness_max)
  loudness_min: 0.5
  loudness_max: 1.5
  mixup: true # mix several stems of same type with some probability (only works for dataset types: 1, 2, 3)
  mixup_probs: [0.2, 0.02]
  mixup_loudness_min: 0.5
  mixup_loudness_max: 1.5
  all:
    channel_shuffle: 0.5 # Set 0 or lower to disable
    random_inverse: 0.1 # inverse track (better lower probability)
    random_polarity: 0.5 # polarity change (multiply waveform to -1)

inference:
  batch_size: 1
  num_overlap: 4
